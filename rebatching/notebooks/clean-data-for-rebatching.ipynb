{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation For Rebatching\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../coded-books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_batches_dataframe(data_path):\n",
    "    \"\"\"Constructs a dataframe of batches from the data in the given path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : str\n",
    "        The path to the data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A dataframe of batches. Each row represents a batch. The columns are:\n",
    "        - ra: The RA who coded the batch.\n",
    "        - batch: The name of the batch.\n",
    "        - batch_path: The path to the directory containing the images for the batch.\n",
    "        - via_json_path: The path to the VIA JSON file for the batch.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(data_path):\n",
    "        raise ValueError('data_path must be a directory')\n",
    "    \n",
    "    batches = []\n",
    "    for ra in os.listdir(data_path):\n",
    "        ra_path = os.path.join(data_path, ra)\n",
    "        for batch in os.listdir(ra_path):\n",
    "            batch_path = os.path.join(ra_path, batch)\n",
    "            json_files = [f for f in os.listdir(batch_path) if f.endswith('.json')]\n",
    "            if len(json_files) != 1:\n",
    "                print(f'Found {len(json_files)} JSON files in \"{batch_path}\". Skipping.')\n",
    "                continue\n",
    "            via_json_path = os.path.join(batch_path, json_files[0])\n",
    "            batches.append({\n",
    "                'ra': ra,\n",
    "                'batch': batch,\n",
    "                'batch_path': batch_path,\n",
    "                'via_json_path': via_json_path\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_via_img_metadata(coded_image):\n",
    "    \"\"\"Check that the image metadata in the VIA JSON file has the correct fields.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coded_image : dict\n",
    "        The image metadata from the VIA JSON file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the metadata is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    if 'filename' not in coded_image:\n",
    "        return False\n",
    "    if 'title' not in coded_image['file_attributes']:\n",
    "        return False\n",
    "    if 'google' not in coded_image['file_attributes']:\n",
    "        return False\n",
    "    if 'identifiable' not in coded_image['file_attributes']:\n",
    "        return False\n",
    "    if 'diversity' not in coded_image['file_attributes']:\n",
    "        return False\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_coded_images_dataframe(batches_df):\n",
    "    \"\"\"Constructs a dataframe of coded images from the given batches dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batches_df : pandas.DataFrame\n",
    "        A dataframe of batches. Each row represents a batch. The columns are:\n",
    "        - ra: The RA who coded the batch.\n",
    "        - batch: The name of the batch.\n",
    "        - batch_path: The path to the directory containing the images for the batch.\n",
    "        - via_json_path: The path to the VIA JSON file for the batch.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A dataframe of coded images. Each row represents an image. The columns are:\n",
    "        - ra: The RA who coded the image.\n",
    "        - batch_path: The path of the batch containing the image.\n",
    "        - batch_name: The name of the batch containing the image.\n",
    "        - image: The name of the image.\n",
    "        - image_path: The path to the image.\n",
    "        - title: The title of the book.\n",
    "        - google: The Google Books link for the book.\n",
    "        - identifiable: Whether the book is identifiable.\n",
    "        - diversity_none: Whether the image contains no diversity.\n",
    "        - diversity_bipoc: Whether the image contains diversity in the form of BIPOC.\n",
    "        - diversity_non_cis_man: Whether the image contains diversity in the form of\n",
    "                                 non cisgendered man.\n",
    "        - diversity_lgbq: Whether the image contains diversity in the form of LGBTQ.\n",
    "        - diversity_non-christian: Whether the image contains diversity in the form of\n",
    "                                   non-Christian.\n",
    "        - diversity_disabled: Whether the image contains diversity in the form of\n",
    "                              disabled.\n",
    "        - diversity_other: Whether the image contains diversity in the form of other.\n",
    "        - diversity_ambiguous: Whether the image contains diversity in the form of\n",
    "                                ambiguous.\n",
    "    \"\"\"\n",
    "    if not set(batches_df.columns) == {'ra', 'batch', 'batch_path', 'via_json_path'}:\n",
    "        raise ValueError('batches_df must have the columns: ra, batch, batch_path, via_json_path')\n",
    "\n",
    "    coded_images = []\n",
    "    for _, row in batches_df.iterrows():\n",
    "        with open(row['via_json_path'], encoding='utf8') as f:\n",
    "            via_json = json.load(f)\n",
    "        for key, coded_image in via_json['_via_img_metadata'].items():\n",
    "            # TODO: this is very hacky. Should be more elegant about checking valid metadata.\n",
    "            flag = True\n",
    "            if not validate_via_img_metadata(coded_image):\n",
    "                print(f'Invalid metadata for image \"{row[\"via_json_path\"]} -> {key}\". Writing default.')\n",
    "                flag = False\n",
    "            \n",
    "            if 'filename' not in coded_image:\n",
    "                print(f'No filename for image \"{row[\"via_json_path\"]} -> {key}\". No default avaliable. Skipping')\n",
    "                continue\n",
    "\n",
    "            ra = row['ra']\n",
    "            batch_path = row['batch_path']\n",
    "            batch_name = row['batch']\n",
    "\n",
    "            image = coded_image['filename']\n",
    "            image_path = os.path.join(batch_path, image)\n",
    "            \n",
    "            title = coded_image['file_attributes']['title'] if flag else ''\n",
    "            google = coded_image['file_attributes']['google'] if flag else ''\n",
    "\n",
    "            identifiable = coded_image['file_attributes']['identifiable'] if flag else 'no'\n",
    "\n",
    "            diversity_none = \"none\" in coded_image['file_attributes']['diversity'] if flag else 'false'\n",
    "            diversity_bipoc = \"bipoc\" in coded_image['file_attributes']['diversity'] if flag else 'false'\n",
    "            diversity_non_cis_man = \"non-cis man\" in coded_image['file_attributes']['diversity'] if flag else 'false'\n",
    "            diverseity_lgbq = \"lgbq\" in coded_image['file_attributes']['diversity'] if flag else 'false'\n",
    "            diversity_non_christian = \"non-christian\" in coded_image['file_attributes']['diversity'] if flag else 'false'\n",
    "            diversity_disabled = \"disabled\" in coded_image['file_attributes']['diversity'] if flag else 'false'\n",
    "            diversity_other = \"other\" in coded_image['file_attributes']['diversity'] if flag else 'false'\n",
    "            diversity_ambiguous = \"ambiguous\" in coded_image['file_attributes']['diversity'] if flag else 'false'\n",
    "\n",
    "            coded_images.append({\n",
    "                'ra': ra,\n",
    "                'batch': batch_name,\n",
    "                'batch_path': batch_path,\n",
    "                'image': image,\n",
    "                'image_path': image_path,\n",
    "                'title': title,\n",
    "                'google': google,\n",
    "                'identifiable': identifiable,\n",
    "                'diversity_none': diversity_none,\n",
    "                'diversity_bipoc': diversity_bipoc,\n",
    "                'diversity_non_cis_man': diversity_non_cis_man,\n",
    "                'diversity_lgbq': diverseity_lgbq,\n",
    "                'diversity_non_christian': diversity_non_christian,\n",
    "                'diversity_disabled': diversity_disabled,\n",
    "                'diversity_other': diversity_other,\n",
    "                'diversity_ambiguous': diversity_ambiguous\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(coded_images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_df = construct_batches_dataframe(data_path)\n",
    "coded_images_df = construct_coded_images_dataframe(batches_df)\n",
    "coded_images_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = coded_images_df[coded_images_df['batch'].str.contains('training')]\n",
    "non_training_data = coded_images_df[~coded_images_df['batch'].str.contains('training')]\n",
    "\n",
    "training_data_needs_rebatching = training_data.drop_duplicates(subset=['image', 'title'])\n",
    "training_data_needs_rebatching = training_data_needs_rebatching.drop_duplicates(subset=['image'])\n",
    "\n",
    "non_training_data_needs_rebatching = non_training_data[non_training_data['identifiable'] == 'no']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebatching_df = pd.concat([training_data_needs_rebatching, non_training_data_needs_rebatching], axis=0, ignore_index=True)\n",
    "rebatching_df = rebatching_df[['ra', 'batch', 'image']]\n",
    "rebatching_df = rebatching_df.drop_duplicates(subset=['image'])\n",
    "rebatching_df = rebatching_df.rename(columns={'batch': 'old_batch',\n",
    "                                              'ra': 'old_ra',})\n",
    "rebatching_df.to_csv('../need-rebatching.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58ed313190bb0b7e91dd2f9a464e3216ab686140ac15e04fa2e2836f55fda08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
