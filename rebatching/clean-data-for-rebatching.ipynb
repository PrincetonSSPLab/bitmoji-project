{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation For Rebatching\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../coded-books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_batches_dataframe(data_path):\n",
    "    \"\"\"Constructs a dataframe of batches from the data in the given path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : str\n",
    "        The path to the data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A dataframe of batches. Each row represents a batch. The columns are:\n",
    "        - ra: The RA who coded the batch.\n",
    "        - batch: The name of the batch.\n",
    "        - batch_path: The path to the directory containing the images for the batch.\n",
    "        - via_json_path: The path to the VIA JSON file for the batch.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(data_path):\n",
    "        raise ValueError('data_path must be a directory')\n",
    "    \n",
    "    batches = []\n",
    "    for ra in os.listdir(data_path):\n",
    "        ra_path = os.path.join(data_path, ra)\n",
    "        for batch in os.listdir(ra_path):\n",
    "            batch_path = os.path.join(ra_path, batch)\n",
    "            json_files = [f for f in os.listdir(batch_path) if f.endswith('.json')]\n",
    "            if len(json_files) != 1:\n",
    "                print(f'Found {len(json_files)} JSON files in \"{batch_path}\". Skipping.')\n",
    "                continue\n",
    "            via_json_path = os.path.join(batch_path, json_files[0])\n",
    "            batches.append({\n",
    "                'ra': ra,\n",
    "                'batch': batch,\n",
    "                'batch_path': batch_path,\n",
    "                'via_json_path': via_json_path\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_via_img_metadata(coded_image):\n",
    "    \"\"\"Check that the image metadata in the VIA JSON file has the correct fields.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coded_image : dict\n",
    "        The image metadata from the VIA JSON file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the metadata is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    if 'filename' not in coded_image:\n",
    "        return False\n",
    "    if 'title' not in coded_image['file_attributes']:\n",
    "        return False\n",
    "    if 'google' not in coded_image['file_attributes']:\n",
    "        return False\n",
    "    if 'identifiable' not in coded_image['file_attributes']:\n",
    "        return False\n",
    "    if 'diversity' not in coded_image['file_attributes']:\n",
    "        return False\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_coded_images_dataframe(batches_df):\n",
    "    \"\"\"Constructs a dataframe of coded images from the given batches dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batches_df : pandas.DataFrame\n",
    "        A dataframe of batches. Each row represents a batch. The columns are:\n",
    "        - ra: The RA who coded the batch.\n",
    "        - batch: The name of the batch.\n",
    "        - batch_path: The path to the directory containing the images for the batch.\n",
    "        - via_json_path: The path to the VIA JSON file for the batch.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A dataframe of coded images. Each row represents an image. The columns are:\n",
    "        - ra: The RA who coded the image.\n",
    "        - batch_path: The path of the batch containing the image.\n",
    "        - batch_name: The name of the batch containing the image.\n",
    "        - image: The name of the image.\n",
    "        - image_path: The path to the image.\n",
    "        - title: The title of the book.\n",
    "        - google: The Google Books link for the book.\n",
    "        - identifiable: Whether the book is identifiable.\n",
    "        - diversity_none: Whether the image contains no diversity.\n",
    "        - diversity_bipoc: Whether the image contains diversity in the form of BIPOC.\n",
    "        - diversity_non_cis_man: Whether the image contains diversity in the form of\n",
    "                                 non cisgendered man.\n",
    "        - diversity_lgbq: Whether the image contains diversity in the form of LGBTQ.\n",
    "        - diversity_non-christian: Whether the image contains diversity in the form of\n",
    "                                   non-Christian.\n",
    "        - diversity_disabled: Whether the image contains diversity in the form of\n",
    "                              disabled.\n",
    "        - diversity_other: Whether the image contains diversity in the form of other.\n",
    "        - diversity_ambiguous: Whether the image contains diversity in the form of\n",
    "                                ambiguous.\n",
    "    \"\"\"\n",
    "    if not set(batches_df.columns) == {'ra', 'batch', 'batch_path', 'via_json_path'}:\n",
    "        raise ValueError('batches_df must have the columns: ra, batch, batch_path, via_json_path')\n",
    "\n",
    "    coded_images = []\n",
    "    for _, row in batches_df.iterrows():\n",
    "        with open(row['via_json_path'], encoding='utf8') as f:\n",
    "            via_json = json.load(f)\n",
    "        for key, coded_image in via_json['_via_img_metadata'].items():\n",
    "            # TODO: this is very hacky. Should be more elegant about checking valid metadata.\n",
    "            flag = True\n",
    "            if not validate_via_img_metadata(coded_image):\n",
    "                print(f'Invalid metadata for image \"{row[\"via_json_path\"]} -> {key}\". Writing default.')\n",
    "                flag = False\n",
    "            \n",
    "            if 'filename' not in coded_image:\n",
    "                print(f'No filename for image \"{row[\"via_json_path\"]} -> {key}\". No default avaliable. Skipping')\n",
    "                continue\n",
    "\n",
    "            ra = row['ra']\n",
    "            batch_path = row['batch_path']\n",
    "            batch_name = row['batch']\n",
    "\n",
    "            image = coded_image['filename']\n",
    "            image_path = os.path.join(batch_path, image)\n",
    "            \n",
    "            title = coded_image['file_attributes']['title'] if flag else ''\n",
    "            title = title.lower()\n",
    "        \n",
    "            google = coded_image['file_attributes']['google'] if flag else ''\n",
    "\n",
    "            identifiable = coded_image['file_attributes']['identifiable'] if flag else 'no'\n",
    "\n",
    "            diversity_none = \"none\" in coded_image['file_attributes']['diversity'] if flag else False\n",
    "            diversity_bipoc = \"bipoc\" in coded_image['file_attributes']['diversity'] if flag else False\n",
    "            diversity_non_cis_man = \"non-cis man\" in coded_image['file_attributes']['diversity'] if flag else False\n",
    "            diverseity_lgbq = \"lgbq\" in coded_image['file_attributes']['diversity'] if flag else False\n",
    "            diversity_non_christian = \"non-christian\" in coded_image['file_attributes']['diversity'] if flag else False\n",
    "            diversity_disabled = \"disabled\" in coded_image['file_attributes']['diversity'] if flag else False\n",
    "            diversity_other = \"other\" in coded_image['file_attributes']['diversity'] if flag else False\n",
    "            diversity_ambiguous = \"ambiguous\" in coded_image['file_attributes']['diversity'] if flag else False\n",
    "\n",
    "            coded_images.append({\n",
    "                'ra': ra,\n",
    "                'batch': batch_name,\n",
    "                'batch_path': batch_path,\n",
    "                'image': image,\n",
    "                'image_path': image_path,\n",
    "                'title': title,\n",
    "                'google': google,\n",
    "                'identifiable': identifiable,\n",
    "                'diversity_none': diversity_none,\n",
    "                'diversity_bipoc': diversity_bipoc,\n",
    "                'diversity_non_cis_man': diversity_non_cis_man,\n",
    "                'diversity_lgbq': diverseity_lgbq,\n",
    "                'diversity_non_christian': diversity_non_christian,\n",
    "                'diversity_disabled': diversity_disabled,\n",
    "                'diversity_other': diversity_other,\n",
    "                'diversity_ambiguous': diversity_ambiguous\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(coded_images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_df = construct_batches_dataframe(data_path)\n",
    "coded_images_df = construct_coded_images_dataframe(batches_df)\n",
    "coded_images_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = coded_images_df[coded_images_df['batch'].str.contains('training')]\n",
    "non_training_data = coded_images_df[~coded_images_df['batch'].str.contains('training')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some images are duplicated across the batches for some reason. This shouldn't have happened.\n",
    "duplicates_in_non_training= non_training_data[non_training_data['image'].isin(training_data['image'])]\n",
    "duplicates_in_training = training_data[training_data['image'].isin(non_training_data['image'])]\n",
    "\n",
    "print(f'Number of non-training duplicates: {len(duplicates_in_non_training)}')\n",
    "print(f'Number of training duplicates: {len(duplicates_in_training)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = pd.concat([duplicates_in_non_training, duplicates_in_training])\n",
    "duplicates = duplicates.sort_values(by=['image', 'batch'])\n",
    "duplicates.to_csv('../duplicates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing images that were coded with the exact same title by all RA's.\n",
    "training_data_needs_rebatching = training_data.drop_duplicates(subset=['image', 'title'])\n",
    "\n",
    "# Removing duplicate images. \n",
    "training_data_needs_rebatching = training_data.drop_duplicates(subset=['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_training_data_needs_rebatching = non_training_data[non_training_data['identifiable'] == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebatching_df = pd.concat([training_data_needs_rebatching, non_training_data_needs_rebatching, duplicates_in_non_training], axis=0, ignore_index=True)\n",
    "rebatching_df = rebatching_df[['ra', 'batch', 'image']]\n",
    "# There should not have been duplicates in this data, but there were.\n",
    "# We are going to rebatch all duplicates.\n",
    "rebatching_df = rebatching_df.drop_duplicates(subset=['image'])\n",
    "rebatching_df = rebatching_df.rename(columns={'batch': 'old_batch',\n",
    "                                              'ra': 'old_ra',})\n",
    "rebatching_df.to_csv('../need-rebatching.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Batches for Duplicate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch Batch 10 Emily has duplicate image user2078_1971_book_3_8.jpg\n",
      "batch Batch 11 Michelle has duplicate image user2113_2607_book_1_1.jpg\n",
      "batch Batch 11 Michelle has duplicate image user2152_2622_book_1_5.jpg\n",
      "batch Batch 12 Michelle has duplicate image user2276_2006_book_17_16.jpg\n",
      "batch Batch 13 Stephanie has duplicate image user2219_2002_book_2_5.jpg\n",
      "batch Batch 14 Stephanie has duplicate image user2156_1995_book_10_11.jpg\n",
      "batch Batch 15 Stephanie has duplicate image user1446_3066_book_3_6.jpg\n",
      "batch Batch 15 Stephanie has duplicate image user1980_3831_book_4_4.jpg\n",
      "batch Batch 15 Stephanie has duplicate image user2281_2010_book_5_15.jpg\n",
      "batch Batch 18 Sabrina has duplicate image user1484_3082_book_3_6.jpg\n",
      "batch Batch 19 Sabrina has duplicate image user2036_3841_book_3_12.jpg\n",
      "batch Batch 20 Nicole has duplicate image user1446_3066_book_15_18.jpg\n",
      "batch Batch 20 Nicole has duplicate image user1492_1233_book_1_5.jpg\n",
      "batch Batch 21 Nicole has duplicate image user2133_4504_book_8_8.jpg\n",
      "batch Batch 22 Nicole has duplicate image user2103_1362_book_3_4.jpg\n",
      "batch Batch 22 Nicole has duplicate image user2156_1995_book_8_9.jpg\n",
      "batch Batch 23 Emily has duplicate image user1996_2566_book_2_1.jpg\n",
      "batch Batch 24 Emily has duplicate image user2152_1989_book_1_2.jpg\n",
      "batch Batch 25 Emily has duplicate image user2000_701_book_2_2.jpg\n",
      "batch Batch 25 Emily has duplicate image user2180_23_book_4_4.jpg\n",
      "batch Batch 26 Stephanie has duplicate image user2024_4487_book_1_5.jpg\n",
      "batch Batch 27 Stephanie has duplicate image user2156_1997_book_8_9.jpg\n",
      "batch Batch 28 Stephanie has duplicate image user1996_2567_book_6_6.jpg\n",
      "batch Batch 29 Stephanie has duplicate image user1521_1842_book_1_3.jpg\n",
      "batch Batch 2a training set has duplicate image user2024_3839_book_1_4.jpg\n",
      "batch Batch 2a training set has duplicate image user2083_1972_book_2_6.jpg\n",
      "batch Batch 2a training set has duplicate image user2133_4504_book_3_2.jpg\n",
      "batch Batch 2a training set has duplicate image user2180_23_book_2_2.jpg\n",
      "batch Batch 2b training set has duplicate image user1433_1806_book_7_10.jpg\n",
      "batch Batch 2b training set has duplicate image user1980_3831_book_1_1.jpg\n",
      "batch Batch 2b training set has duplicate image user2152_1987_book_2_8.jpg\n",
      "batch Batch 31 Stephanie has duplicate image user1505_3084_book_4_6.jpg\n",
      "batch Batch 32 Sabrina has duplicate image user1996_2568_book_3_13.jpg\n",
      "batch Batch 32 Sabrina has duplicate image user2000_1338_book_2_5.jpg\n",
      "batch Batch 33 Sabrina has duplicate image user2083_1973_book_3_4.jpg\n",
      "batch Batch 34 Emily has duplicate image user1433_1806_book_6_9.jpg\n",
      "batch Batch 34 Emily has duplicate image user2052_3213_book_9_14.jpg\n",
      "batch Batch 36 Stephanie has duplicate image user2156_1996_book_10_11.jpg\n",
      "batch Batch 3a training set has duplicate image user1492_1233_book_4_8.jpg\n",
      "batch Batch 3a training set has duplicate image user1505_3084_book_11_13.jpg\n",
      "batch Batch 3a training set has duplicate image user2103_1363_book_7_9.jpg\n",
      "batch Batch 4b training set has duplicate image user1446_3066_book_7_10.jpg\n",
      "batch Batch 4b training set has duplicate image user1540_3717_book_4_4.jpg\n",
      "batch Batch 5 training set has duplicate image user2029_708_book_5_4.jpg\n",
      "batch Batch 8 Emily has duplicate image user1436_577_book_1_5.jpg\n",
      "batch Batch 8 Emily has duplicate image user2133_4504_book_6_6.jpg\n",
      "Number of duplicate images: 46\n"
     ]
    }
   ],
   "source": [
    "batches_path = '../batches'\n",
    "\n",
    "# check all individual directories for duplicate images\n",
    "for batch in os.listdir(batches_path):\n",
    "    batch_path = os.path.join(batches_path, batch)\n",
    "    images = os.listdir(batch_path)\n",
    "    if len(images) != len(set(images)):\n",
    "        print(f'batch {batch} has duplicate images.')\n",
    "\n",
    "# check for duplicate images across all batches\n",
    "all_images = set()\n",
    "count = 0\n",
    "for batch in os.listdir(batches_path):\n",
    "    batch_path = os.path.join(batches_path, batch)\n",
    "    batch_images = os.listdir(batch_path)\n",
    "    for image in batch_images:\n",
    "        if image in all_images:\n",
    "            count += 1\n",
    "            print(f'batch {batch} has duplicate image {image}')\n",
    "    all_images.update(os.listdir(batch_path))\n",
    "\n",
    "print(f'Number of duplicate images: {count}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Images That Were Not Coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# check for images that were not coded \n",
    "batches_path = '../batches'\n",
    "\n",
    "all_images = set()\n",
    "for batch in os.listdir(batches_path):\n",
    "    batch_path = os.path.join(batches_path, batch)\n",
    "    batch_images = [file for file in os.listdir(batch_path) if not file.endswith('.json')]\n",
    "    all_images.update(batch_images)\n",
    "\n",
    "    coded_images = set(coded_images_df['image'])\n",
    "    uncoded_images = all_images - coded_images\n",
    "\n",
    "print(uncoded_images)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Images That Need Rebatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_batches_path = '../coded-books'\n",
    "output_path = '../needs-rebatching-12-14-2022'\n",
    "\n",
    "def create_path_from_row(row):\n",
    "    return os.path.join(ra_batches_path, row['old_ra'], row['old_batch'], row['image'])\n",
    "\n",
    "rebatching_df['path'] = rebatching_df.apply(lambda x: create_path_from_row(x), axis=1)\n",
    "# copy images to new directory\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "for index, row in rebatching_df.iterrows():\n",
    "    shutil.copy(row['path'], output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Metrics\n",
    "Generating insights into how the RA's are coding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bar chart for each ra where the x axis is the ra and the y axis shows the distribution of images\n",
    "ra_batches = coded_images_df.groupby(['ra', 'identifiable'])\n",
    "ra_batches = ra_batches['image'].count().unstack('identifiable').fillna(0)\n",
    "ra_batches = ra_batches.sort_values(by=['yes'], ascending=False)\n",
    "\n",
    "# set styles for the bar chart\n",
    "plt.style.use('bmh')\n",
    "colors = ['#323031', '#FFC857', '#DB3A34', '#084C61', '#177E89']\n",
    "ax = ra_batches.plot.bar(stacked=False, figsize=(20, 10), color=colors)\n",
    "ax.set_facecolor('#EEEEEE')\n",
    "ax.set_xlabel('RA', fontsize=14)\n",
    "ax.set_ylabel('Number of Images', fontsize=14)\n",
    "ax.set_title('Distribution of Codable Images by RA', fontsize=18)\n",
    "ax.legend(loc='upper right', fontsize=14)\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bar chart for each ra where the x axis is the ra and the y axis shows the distribution of diversity categories\n",
    "ra_batches = coded_images_df.groupby(['ra'])\n",
    "# get counts for each diversity category\n",
    "ra_batches = ra_batches[['diversity_none', 'diversity_bipoc', 'diversity_non_cis_man',\n",
    "                        'diversity_lgbq', 'diversity_non_christian', 'diversity_disabled',\n",
    "                        'diversity_other', 'diversity_ambiguous']].sum().fillna(0)\n",
    "\n",
    "ra_batches = ra_batches.sort_values(by=['diversity_none'], ascending=False)\n",
    "\n",
    "\n",
    "# set styles for the bar chart\n",
    "plt.style.use('bmh')\n",
    "colors = ['#f94144','#f9844a','#f9c74f','#90be6d','#43aa8b','#4d908e','#577590','#277da1']\n",
    "ax = ra_batches.plot.bar(stacked=False, figsize=(20, 10), color=colors)\n",
    "ax.set_facecolor('#EEEEEE')\n",
    "ax.set_xlabel('RA', fontsize=14)\n",
    "ax.set_ylabel('Number of Images', fontsize=14)\n",
    "ax.set_title('Distribution of Coded Diversity by RA', fontsize=18)\n",
    "ax.legend(loc='upper right', fontsize=14)\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58ed313190bb0b7e91dd2f9a464e3216ab686140ac15e04fa2e2836f55fda08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
